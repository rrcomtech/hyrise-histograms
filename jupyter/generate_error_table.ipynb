{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0ee5c2-433b-49cd-b336-123b375a7b9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# generate_error_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62db79-9d8b-4164-9c3e-da355e58d639",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfa926-64b4-464c-9276-997d740877d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8953de-426f-41a2-a331-d44f0184cca0",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852360f6-557a-4dc1-88ab-5eb670be08fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('final_data/equaldistinctcount_20230221.csv')\n",
    "df1 = pd.read_csv('final_data/equiheight_20230221.csv')\n",
    "df2 = pd.read_csv('final_data/equiwidth_20230221.csv')\n",
    "df3 = pd.read_csv('final_data/gdy_20230221.csv')\n",
    "df4 = pd.read_csv('final_data/maxdiff_20230221.csv')\n",
    "df5 = pd.read_csv('final_data/maxdiffarea_20230309.csv')\n",
    "df = pd.concat([df0, df1, df2, df3, df4, df5], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59925590-8eb8-4618-b99a-564ca65f2dc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## generate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c58e36-b836-4dbe-a347-5abe4d4dcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_errors(df):\n",
    "    df = df.copy()  # Convenience\n",
    "    \n",
    "    df['absolute_error'] = np.absolute(df['estimated_output'] - df['real_output'])\n",
    "    df['relative_error'] = df['absolute_error'] / df['real_output']\n",
    "    df['x'] = df['estimated_output'] / df['real_output']\n",
    "    df['1/x'] = 1 / df['x']\n",
    "    df['q_error'] = df[['x','1/x']].max(axis=1)\n",
    "    df['real_output_lower_bound'] = df['real_output']\n",
    "    df['real_output_lower_bound'] = df['real_output_lower_bound'].clip(1)\n",
    "    df['estimated_output_lower_bound'] = df['estimated_output']\n",
    "    df['estimated_output_lower_bound'] = df['estimated_output_lower_bound'].clip(1)\n",
    "    df['pseudo_x'] = df['estimated_output_lower_bound'] / df['real_output_lower_bound']\n",
    "    df['pseudo_1/x'] = 1 / df['pseudo_x']\n",
    "    df['pseudo_q_error'] = df[['pseudo_x','pseudo_1/x']].max(axis=1)\n",
    "    df['mean_squared_error'] = df['absolute_error'] ** 2\n",
    "    df.drop(['x', '1/x', 'real_output_lower_bound', 'estimated_output_lower_bound', 'pseudo_x', 'pseudo_1/x'], axis=1, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235f5fa-a6cd-4daf-a33f-1077f0155fa4",
   "metadata": {},
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba3595-ad3d-4a4c-a708-dac8b698e0a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### with_NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135fb8a-d638-44fb-9762-670b0096340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_errors = generate_errors(df)\n",
    "df_with_errors\n",
    "\n",
    "df_with_errors.groupby([#\"operator_type\",\n",
    "                        \"benchmark\",\n",
    "                        \"histogram\"]).agg(root_mean_squared_error=(\"mean_squared_error\", lambda x: np.sqrt(np.mean(x))),\n",
    "                                          mean_absolute_error=(\"absolute_error\", np.mean),\n",
    "                                          mean_relative_error=(\"relative_error\", np.mean),\n",
    "                                          mean_q_error=(\"q_error\", np.mean),\n",
    "                                          mean_pseudo_q_error=(\"pseudo_q_error\", np.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64f64e-a6e9-4a99-8f3d-2b16721cfff5",
   "metadata": {},
   "source": [
    "### without_NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45629f-28ae-437c-9f85-0fb8494cbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_before = len(df)\n",
    "df = df.drop(df[df.real_output == 0].index)\n",
    "print(f\"Removed {len(df)-size_before} ({(size_before-len(df))/size_before:.2%}) rows because the 'real_output' cell was zero.\")\n",
    "df = df.drop(df[df.estimated_output == 0].index)\n",
    "print(f\"Removed {len(df)-size_before} ({(size_before-len(df))/size_before:.2%}) rows because the 'estimated_output' cell was zero.\")\n",
    "\n",
    "df_with_errors = generate_errors(df)\n",
    "\n",
    "# print as the resulting table is cut by Jupyter\n",
    "for operator in pd.unique(df_with_errors.operator_type):\n",
    "    filtered = df_with_errors.query(\"operator_type == @operator\")\n",
    "    result = filtered.groupby([\"operator_type\",\n",
    "                               \"benchmark\",\n",
    "                               \"histogram\"]).agg(root_mean_squared_error=(\"mean_squared_error\", lambda x: np.sqrt(np.mean(x))),\n",
    "                                                 mean_absolute_error=(\"absolute_error\", np.mean),\n",
    "                                                 mean_relative_error=(\"relative_error\", np.mean),\n",
    "                                                 mean_q_error=(\"q_error\", np.mean),\n",
    "                                                 mean_pseudo_q_error=(\"pseudo_q_error\", np.mean))\n",
    "    display(result)\n",
    "    melted_results = pd.melt(result.reset_index(), id_vars=[\"benchmark\", \"histogram\"],\n",
    "                             value_vars=[\"root_mean_squared_error\", \"mean_absolute_error\",\n",
    "                                         \"mean_relative_error\", \"mean_q_error\", \"mean_pseudo_q_error\"],\n",
    "                             var_name=\"metric\")\n",
    "    g = sns.FacetGrid(melted_results, col=\"benchmark\", row=\"metric\", sharey=False, aspect=2)\n",
    "    g.map_dataframe(sns.barplot, x=\"histogram\", y=\"value\", hue=\"histogram\", palette=\"Set3\")\n",
    "    g.add_legend()\n",
    "    plt.savefig(f\"{operator}_facet.pdf\")\n",
    "    plt.show()\n",
    "    display(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2160f-2d6a-4d1c-b841-d79a097feecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## compare_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba039d-f46b-40d4-9ec9-ca84014b87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby([\"benchmark\", \"histogram\", \"query\", \"operator_type\"]).size()\n",
    "\n",
    "queries = df[[\"benchmark\", \"query\"]].drop_duplicates()\n",
    "\n",
    "# super inefficient, doesn't matter for now\n",
    "op_counts = {}\n",
    "for _, outer_benchmark, outer_query in queries.itertuples():\n",
    "    for (_1, benchmark, histogram, query, operator_type, count) in grouped.reset_index().itertuples():\n",
    "        if outer_benchmark == benchmark and outer_query == query:\n",
    "            if (benchmark, query, operator_type) not in op_counts:\n",
    "                op_counts[(benchmark, query, operator_type)] = count\n",
    "                continue\n",
    "\n",
    "            if op_counts[(benchmark, query, operator_type)] != count:\n",
    "                print(f\"WARNING: different value of {count} (previously {op_counts[(benchmark, query, operator_type)]}) for {benchmark}, query {query}, op {operator_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc980f97-aaed-4861-9eca-e90f07374602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
